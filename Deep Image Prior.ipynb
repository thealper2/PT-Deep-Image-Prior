{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d8dac0-de83-4b0d-b86f-2154bb758c09",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeefa017-3976-4e74-8e76-338203e45c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fb93e-298d-46a0-a17f-f52b4d41ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d4ac7-3bb6-4527-be8b-4f6a82cac4df",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e6e5b-e14b-4534-a0f7-f2ef4506c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"car-cartoon.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c63f73-edc4-4f2d-87a3-fa055ede0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e1759-b853-43c7-82ac-1f457c8c35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a03d5-feb5-4000-90da-7b2fbe90089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((h, w), interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976beca1-9601-4fe8-95ff-56eb6c7170f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = transform(image) \n",
    "image = image.permute(1, 2, 0)\n",
    "image = image.unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2d50f-cd2e-466d-933d-83121c8f1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ba6ab-dc53-4223-b231-af11561e5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df7a7f-a70b-4087-9039-22b71b91a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image = (image + torch.randn_like(image) * 0.1).clip(0, 1).transpose(2, 3).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44705cd9-59b8-4208-a0f6-931a300d4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corrupted_image[0].transpose(0, 1).transpose(1, 2).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e96ce-9ed5-433d-8093-292cf9787b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image = corrupted_image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f00982-9912-4bae-bf08-be8b9ebeec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(corrupted_image.shape) * 0.1\n",
    "z = z.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fb7f5-b624-4ec4-9ebd-e52b9d720734",
   "metadata": {},
   "source": [
    "# Deep Image Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5d6a8-97f4-4738-82fa-946605054221",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepImagePrior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepImagePrior, self).__init__()\n",
    "\n",
    "        self.down_blocks = nn.ModuleList([\n",
    "            self._down_block(3, 8, 3),\n",
    "            self._down_block(8, 16, 3),\n",
    "            self._down_block(16, 32, 3),\n",
    "            self._down_block(32, 64, 3),\n",
    "            self._down_block(64, 128, 3)\n",
    "        ])\n",
    "\n",
    "        self.skip_blocks = nn.ModuleList([\n",
    "            self._skip_block(32, 4, 1),\n",
    "            self._skip_block(64, 4, 1)\n",
    "        ])\n",
    "\n",
    "        self.up_blocks = nn.ModuleList([\n",
    "            self._up_block(128 + 4, 128, 3),\n",
    "            self._up_block(128 + 4, 64, 3),\n",
    "            self._up_block(64, 32, 3),\n",
    "            self._up_block(32, 16, 3),\n",
    "            self._up_block(16, 8, 3)\n",
    "        ])\n",
    "\n",
    "        self.conv_out = nn.Conv2d(8, 3, 1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def _down_block(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def _skip_block(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def _up_block(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for i, down in enumerate(self.down_blocks):\n",
    "            x = down(x)\n",
    "            if i == 2:\n",
    "                skip_connections.append(self.skip_blocks[0](x))\n",
    "            elif i == 3:\n",
    "                skip_connections.append(self.skip_blocks[1](x))\n",
    "\n",
    "        x = self.up_blocks[0](torch.cat((skip_connections[1][:, :, 4:-4, 6:-6], x), dim=1))\n",
    "        x = self.up_blocks[1](torch.cat((skip_connections[0][:, :, 8:-8, 12:-12], x), dim=1))\n",
    "        x = self.up_blocks[2](x)\n",
    "        x = self.up_blocks[3](x)\n",
    "        x = self.up_blocks[4](x)\n",
    "\n",
    "        return torch.sigmoid(self.conv_out(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e828b-d5e1-4fd7-b9d9-ffb2ec85c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_image_prior = DeepImagePrior()\n",
    "deep_image_prior.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7900597-fea0-45b5-abd7-34afbdcf3b7d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a625a-3133-47c0-b045-9bea8f3d4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ba70c-c961-4992-9098-e8763025c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(deep_image_prior.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bf347-d1b4-48b8-9734-cdee47cf0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64594af-803d-4954-96b3-bbb67f2df949",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a766e-a10b-4123-8ecf-f6099e778d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    predicted_image = deep_image_prior.forward(z)\n",
    "    loss = F.mse_loss(predicted_image, corrupted_image)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"[Epoch {epoch}/{num_epochs}], [Loss: {loss.item():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944185b-2cef-43b7-b0d8-52d7a949f416",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ea09d-ba78-499b-9f88-746e284a553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d59fb-eea2-4b1c-bb84-c3498009b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(15, 5))\n",
    "\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].imshow(image[0])\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].set_title(\"Corrupted Image\")\n",
    "axes[1].imshow(np.transpose(corrupted_image.cpu().detach()[0], (1, 2, 0)))\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].set_title(\"Predicted Image\")\n",
    "axes[2].imshow(np.transpose(predicted_image.cpu().detach()[0], (1, 2, 0)))\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44f765-3a38-4def-a385-5a766ce266e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
